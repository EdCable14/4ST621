{"title":"Course Introduction","markdown":{"yaml":{"title":"Course Introduction","author":"Adam Cabla"},"containsRefs":false,"markdown":"\n\nWelcome to the course 4ST621 -- Probability Theory and Mathematical Statistics I.\n\nAs the name suggests, this course has two main parts. So, what is the difference between probability and statistics?\n\nIn probability theory, we deal with the following question: Given some assumptions about the generating process, what can we say about (possible) data?\n\nIn (inferential) statistics, we ask quite the opposite question: Given the data, what can we say about the (possible) generating process?  \n\nIn the first (longer) part, we will start with some basic terms and operations used upon probabilities, which will lead us to the Bayes theorem, a potent tool for thinking about data. Then, we will move to random variables, distributing probabilities among real numbers and what characteristics can come from these distributions. Generalising into two dimensions, we will also add problematics of relations between random variables. Then, with some general ideas in mind, we will move to specific probability distributions, or probabilistic models, arising from various assumptions. This tour is finished with stochastic convergences, which provide reasoning machinery for inferential statistics, connecting it with the probability theory.\n\nIn the second (shorter) part, we will start with the basics of sampling -- how data come into existence and how we can use stochastic convergences or some other assumptions to model the probability distribution of various statistics. We will make a slight detour into the area of point estimates to cover important notions of estimators' variability and bias. After this, we will return to the sampling theory and see how to use it to test various claims about the generating process. Hypothesis testing is an essential tool in the statistical bag if done correctly, which is not so easy without understanding some basic and often overlooked philosophical connections. To finish the course, we will introduce confidence intervals, which are dual to hypothesis testing but bring additional information.\n\nThis course is by no means a complete treatise on the subjects outlined in the previous paragraphs. It is rather an introductory, sometimes more and sometimes less comprehensive, into the topics.\n\nPlease avoid falling into the Dunning-Kruger-like trap of being overconfident after learning the basics.\n","srcMarkdownNoYaml":"\n\nWelcome to the course 4ST621 -- Probability Theory and Mathematical Statistics I.\n\nAs the name suggests, this course has two main parts. So, what is the difference between probability and statistics?\n\nIn probability theory, we deal with the following question: Given some assumptions about the generating process, what can we say about (possible) data?\n\nIn (inferential) statistics, we ask quite the opposite question: Given the data, what can we say about the (possible) generating process?  \n\nIn the first (longer) part, we will start with some basic terms and operations used upon probabilities, which will lead us to the Bayes theorem, a potent tool for thinking about data. Then, we will move to random variables, distributing probabilities among real numbers and what characteristics can come from these distributions. Generalising into two dimensions, we will also add problematics of relations between random variables. Then, with some general ideas in mind, we will move to specific probability distributions, or probabilistic models, arising from various assumptions. This tour is finished with stochastic convergences, which provide reasoning machinery for inferential statistics, connecting it with the probability theory.\n\nIn the second (shorter) part, we will start with the basics of sampling -- how data come into existence and how we can use stochastic convergences or some other assumptions to model the probability distribution of various statistics. We will make a slight detour into the area of point estimates to cover important notions of estimators' variability and bias. After this, we will return to the sampling theory and see how to use it to test various claims about the generating process. Hypothesis testing is an essential tool in the statistical bag if done correctly, which is not so easy without understanding some basic and often overlooked philosophical connections. To finish the course, we will introduce confidence intervals, which are dual to hypothesis testing but bring additional information.\n\nThis course is by no means a complete treatise on the subjects outlined in the previous paragraphs. It is rather an introductory, sometimes more and sometimes less comprehensive, into the topics.\n\nPlease avoid falling into the Dunning-Kruger-like trap of being overconfident after learning the basics.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"Course_Intro.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","editor":"visual","theme":"cosmo","title":"Course Introduction","author":"Adam Cabla"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}