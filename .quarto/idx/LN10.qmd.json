{"title":"Point estimates","markdown":{"yaml":{"title":"Point estimates","author":"Adam Cabla"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nWe will introduce the first basic concepts in point estimates in frequentist statistics. To remind you, frequentist statistics is about long-term properties; here, we introduce the long-term properties of the statistics we use to estimate parameters and the most common methods to construct these statistics.\n\nThe *long-term* in this setting means *under repeated sampling*. That is, if you repeat the sample of a given size over and over and over, and you write down values of the statistics across this theoretically infinite batch of samples, what are the properties of these statistics? Recall the previous chapter by introducing the characteristics of statistics and their sampling distributions.\n\nFirst, we need to distinguish three terms:\n\n***The estimator T*** is a statistic that is used to estimate something. This is a random variable, and the properties of this random variable are ofinterest.\n\n***The estimand*** is what we want to estimate, e.g., the parameter $\\theta$ of a chosen probability distribution. This is a constant with no probabilistic properties in our frequentist playbook.\n\n***The estimate***is a realisation; it is the estimator's specific value, ***t***, calculated in the data.\n\n## Basic properties of point estimators\n\nWe instinctively want our estimators to be connected to the estimands somehow. We would like them to have some properties, and we should be aware that there is sometimes even a trade-off between these properties. Intuitively, the estimator should be, on average, as close to the estimand as possible. This closeness can be divided into two properties - how far away it is on the long-term average and how far away it is in its individual realisations (estimates).\n\n### Bias\n\nThe first intuitive property can be written down this way:\n\n$$\nE(T)=\\theta\n$$\n\nThis means that the expected value of our estimator should be equal to the parameter we are about to estimate with it. The property is called unbiasedness and is often not achieved. But a softer version, called asymptotic unbiasedness, does exist:\n\n$$\nE(\\textbf{T})\\xrightarrow{n\\to\\infty}\\theta\n$$\n\nWe can calculate how far away the expectation is from the reality in the quantification of bias:\n\n$$\nb(T)=E(T)-\\theta\n$$\n\nAnd rewrite both properties as\n\n$$\nb(T)=0\n$$\n\n$$\nb(T)\\xrightarrow{n\\to\\infty}0\n$$\n\n### Consistency\n\nBias represents *systematic error*. The second type of error is *random,* which we mathematically represent as the variance of the estimator $Var(T)$.\n\nNow, the consistency property connects the two properties: systematic error, which is zero (unbiasedness) or going down (asymptotic unbiasedness), and random errors, which go down with the increasing number of observations. So, the two necessary and sufficient conditions of consistency are:\n\n$$\nb(T)\\xrightarrow{n\\to\\infty}0\n$$\n\n$$ Var(T)\\xrightarrow{n\\to\\infty}0 $$\n\nConsistency means that the more data we observe, the better our ***estimator*** is on the long-term average.\n\n### Accuracy\n\nHow well is our estimator doing on a long-term average? Since there are two sources of the error, we can combine them to create an overall error evaluation called *mean squared* error:\n\n$$\nMSE(T)=E \\left(\\left(T-\\theta\\right)^2\\right)=\\left(b\\left(T\\right)\\right)^2+Var(T)\n$$\n\nThe mean squared error tells us what the expected squared error of the estimator is regarding the estimated parameter $\\theta$. It is composed of the squared value of the bias and variance of the estimator. If the estimator is unbiased, then the mean squared error is the estimator's variance only.\n\nBecause MSE is, similarly to variance, in squared units of the random variable, it is often considered more useful to communicate its square root called *root mean squared error,* which is in the units of the random variable:\n\n$$\nRMSE(T)=\\sqrt{MSE(T)}\n$$\n\n## Basic methods of construction\n\nEstimators can be constructed in many ways, ranging from the *look outside-of-the-window* method to more sophisticated techniques. Generally, the common basic approaches can be divided into two groups: one that matches some theoretical properties of the distribution to similar properties of the data, and the second optimises the selected criterion of fit. From the first group, we will glance at moment-matching and quantile-matching methods; from the second, we will focus on the most commonly applied method - maximum likelihood estimation.\n\n### Method of Moments\n\nThe method of moments is based on matching theoretical moments of a given probability distribution with empirical moments calculated in the sample. Take, for example, raw moments:\n\n$$\n\\mu_k´=\\overline{x_k}\n$$\n\nThis method can be adapted to use various types of moments (central, standardised, L-moments, TL-moments,...). Still, in its simple version, you create as many equations as the number of parameters you need to estimate and start from the bottom $k=1,2,...$.\n\nThis method was used for its simplicity and usually yields consistent estimators. On the other hand, the estimators are often worse in terms of accuracy than other options and have some other disadvantages.\n\nIt also serves as a teaching introduction to the generalised method of moments applicable under certain conditions or as a first-order solution before proceeding to the maximum likelihood estimate.\n\n### Method of Quantiles\n\nAnother example of the matching method is the method of quantiles, but instead of matching moments, it matches theoretical quantiles $x_p$ with empirical quantiles $\\widetilde{x_p}$ for various values of *P*.\n\nThis method is specifically useful when you want to estimate probability distribution with specific theoretical quantiles of interest, like, e.g. 95% quantile of the log-normal distribution for risk estimate.\n\n### Maximum likelihood method\n\nThe last method of finding estimators in this short list is probably the most common and powerful. Let´s first introduce the concept of likelihood and distinguish it from the joint probability distribution of the sample.\n\nWe start with the assumption that our sample comes from a random sampling procedure (or unchanging data-generating process). In such a case, individual values are drawn from a sequence of independent identically distributed random variables, and their joint probability distribution can be written as the product of individual densities which are identical:\n\n$$f(\\textbf{x},\\theta)=\\prod_{i=1}^n f(x_i,\\theta)$$This is a probability function of fixed parameter $\\theta$ and varying data. This answers the question: What are the probabilities of various datasets if the given parameter has this value?\n\nHowever, it can´t be presented as varying once the dataset is known and fixed. Still, we can switch the idea and ask a different question: if the given dataset looks like this, what are its probabilities under different possible values of the parameter $\\theta$? That is what the likelihood function presents:\n\n$$\nL(x;\\theta)=\\prod_{i=1}^{n}f(x_i,\\theta)\n$$\n\nTo repeat: probability density is the probability of varying data under a fixed value of the parameter; likelihood is the probability of fixed data under a varying value of the parameter.\n\nMaximum likelihood estimators arise from maximising likelihood function; that is, they answer the question: under what value of parameter $\\theta$ arise data at hand with the highest probability?\n\nUnder some general conditions, the likelihood function is unimodal and its maximum can be found using partial derivations:\n\n$$\n\\frac{\\partial L(\\textbf{x},\\theta)}{\\partial \\theta}=0\n$$\n\nThe problem with this is two-fold: analytically, it is quite difficult to find partial derivations of the product. Numerically, this product usually goes too quickly to zero, and the procedure cannot distinguish its value and collapses.\n\nPractically, both of these problems can be solved by using the log-likelihood function, which transforms the product into a sum:\n\n$$\nl(\\textbf{x};\\theta)=log\\left(L(\\textbf{x};\\theta)  \\right)=\\sum_{i=1}^{n}log(f(x_i;\\theta))\n$$\n\nBecause this transformation is monotonic, we can find the maximum at the same point by partial derivation:\n\n$$\n\\frac{\\partial l(\\textbf{x};\\theta)}{\\partial \\theta}=0\n$$\n\nMaximum likelihood estimators are often well-behaved with the following properties:\n\n-   (Asymptotically) unbiased\n\n-   Consistent\n\n-   Asymptotically best linear unbiased estimators (lowest variance among unbiased estimators)\n\n-   Asymptotically having normal distribution.\n\nThe last point is vital for inferences about estimands. One can see that these properties are often asymptotical, i.e. they should be considered with caution. But generally speaking, maximum likelihood estimators are usually the optimal way to go for medium to large samples and typically have good properties even for small sample sizes.\n","srcMarkdownNoYaml":"\n\n## Introduction\n\nWe will introduce the first basic concepts in point estimates in frequentist statistics. To remind you, frequentist statistics is about long-term properties; here, we introduce the long-term properties of the statistics we use to estimate parameters and the most common methods to construct these statistics.\n\nThe *long-term* in this setting means *under repeated sampling*. That is, if you repeat the sample of a given size over and over and over, and you write down values of the statistics across this theoretically infinite batch of samples, what are the properties of these statistics? Recall the previous chapter by introducing the characteristics of statistics and their sampling distributions.\n\nFirst, we need to distinguish three terms:\n\n***The estimator T*** is a statistic that is used to estimate something. This is a random variable, and the properties of this random variable are ofinterest.\n\n***The estimand*** is what we want to estimate, e.g., the parameter $\\theta$ of a chosen probability distribution. This is a constant with no probabilistic properties in our frequentist playbook.\n\n***The estimate***is a realisation; it is the estimator's specific value, ***t***, calculated in the data.\n\n## Basic properties of point estimators\n\nWe instinctively want our estimators to be connected to the estimands somehow. We would like them to have some properties, and we should be aware that there is sometimes even a trade-off between these properties. Intuitively, the estimator should be, on average, as close to the estimand as possible. This closeness can be divided into two properties - how far away it is on the long-term average and how far away it is in its individual realisations (estimates).\n\n### Bias\n\nThe first intuitive property can be written down this way:\n\n$$\nE(T)=\\theta\n$$\n\nThis means that the expected value of our estimator should be equal to the parameter we are about to estimate with it. The property is called unbiasedness and is often not achieved. But a softer version, called asymptotic unbiasedness, does exist:\n\n$$\nE(\\textbf{T})\\xrightarrow{n\\to\\infty}\\theta\n$$\n\nWe can calculate how far away the expectation is from the reality in the quantification of bias:\n\n$$\nb(T)=E(T)-\\theta\n$$\n\nAnd rewrite both properties as\n\n$$\nb(T)=0\n$$\n\n$$\nb(T)\\xrightarrow{n\\to\\infty}0\n$$\n\n### Consistency\n\nBias represents *systematic error*. The second type of error is *random,* which we mathematically represent as the variance of the estimator $Var(T)$.\n\nNow, the consistency property connects the two properties: systematic error, which is zero (unbiasedness) or going down (asymptotic unbiasedness), and random errors, which go down with the increasing number of observations. So, the two necessary and sufficient conditions of consistency are:\n\n$$\nb(T)\\xrightarrow{n\\to\\infty}0\n$$\n\n$$ Var(T)\\xrightarrow{n\\to\\infty}0 $$\n\nConsistency means that the more data we observe, the better our ***estimator*** is on the long-term average.\n\n### Accuracy\n\nHow well is our estimator doing on a long-term average? Since there are two sources of the error, we can combine them to create an overall error evaluation called *mean squared* error:\n\n$$\nMSE(T)=E \\left(\\left(T-\\theta\\right)^2\\right)=\\left(b\\left(T\\right)\\right)^2+Var(T)\n$$\n\nThe mean squared error tells us what the expected squared error of the estimator is regarding the estimated parameter $\\theta$. It is composed of the squared value of the bias and variance of the estimator. If the estimator is unbiased, then the mean squared error is the estimator's variance only.\n\nBecause MSE is, similarly to variance, in squared units of the random variable, it is often considered more useful to communicate its square root called *root mean squared error,* which is in the units of the random variable:\n\n$$\nRMSE(T)=\\sqrt{MSE(T)}\n$$\n\n## Basic methods of construction\n\nEstimators can be constructed in many ways, ranging from the *look outside-of-the-window* method to more sophisticated techniques. Generally, the common basic approaches can be divided into two groups: one that matches some theoretical properties of the distribution to similar properties of the data, and the second optimises the selected criterion of fit. From the first group, we will glance at moment-matching and quantile-matching methods; from the second, we will focus on the most commonly applied method - maximum likelihood estimation.\n\n### Method of Moments\n\nThe method of moments is based on matching theoretical moments of a given probability distribution with empirical moments calculated in the sample. Take, for example, raw moments:\n\n$$\n\\mu_k´=\\overline{x_k}\n$$\n\nThis method can be adapted to use various types of moments (central, standardised, L-moments, TL-moments,...). Still, in its simple version, you create as many equations as the number of parameters you need to estimate and start from the bottom $k=1,2,...$.\n\nThis method was used for its simplicity and usually yields consistent estimators. On the other hand, the estimators are often worse in terms of accuracy than other options and have some other disadvantages.\n\nIt also serves as a teaching introduction to the generalised method of moments applicable under certain conditions or as a first-order solution before proceeding to the maximum likelihood estimate.\n\n### Method of Quantiles\n\nAnother example of the matching method is the method of quantiles, but instead of matching moments, it matches theoretical quantiles $x_p$ with empirical quantiles $\\widetilde{x_p}$ for various values of *P*.\n\nThis method is specifically useful when you want to estimate probability distribution with specific theoretical quantiles of interest, like, e.g. 95% quantile of the log-normal distribution for risk estimate.\n\n### Maximum likelihood method\n\nThe last method of finding estimators in this short list is probably the most common and powerful. Let´s first introduce the concept of likelihood and distinguish it from the joint probability distribution of the sample.\n\nWe start with the assumption that our sample comes from a random sampling procedure (or unchanging data-generating process). In such a case, individual values are drawn from a sequence of independent identically distributed random variables, and their joint probability distribution can be written as the product of individual densities which are identical:\n\n$$f(\\textbf{x},\\theta)=\\prod_{i=1}^n f(x_i,\\theta)$$This is a probability function of fixed parameter $\\theta$ and varying data. This answers the question: What are the probabilities of various datasets if the given parameter has this value?\n\nHowever, it can´t be presented as varying once the dataset is known and fixed. Still, we can switch the idea and ask a different question: if the given dataset looks like this, what are its probabilities under different possible values of the parameter $\\theta$? That is what the likelihood function presents:\n\n$$\nL(x;\\theta)=\\prod_{i=1}^{n}f(x_i,\\theta)\n$$\n\nTo repeat: probability density is the probability of varying data under a fixed value of the parameter; likelihood is the probability of fixed data under a varying value of the parameter.\n\nMaximum likelihood estimators arise from maximising likelihood function; that is, they answer the question: under what value of parameter $\\theta$ arise data at hand with the highest probability?\n\nUnder some general conditions, the likelihood function is unimodal and its maximum can be found using partial derivations:\n\n$$\n\\frac{\\partial L(\\textbf{x},\\theta)}{\\partial \\theta}=0\n$$\n\nThe problem with this is two-fold: analytically, it is quite difficult to find partial derivations of the product. Numerically, this product usually goes too quickly to zero, and the procedure cannot distinguish its value and collapses.\n\nPractically, both of these problems can be solved by using the log-likelihood function, which transforms the product into a sum:\n\n$$\nl(\\textbf{x};\\theta)=log\\left(L(\\textbf{x};\\theta)  \\right)=\\sum_{i=1}^{n}log(f(x_i;\\theta))\n$$\n\nBecause this transformation is monotonic, we can find the maximum at the same point by partial derivation:\n\n$$\n\\frac{\\partial l(\\textbf{x};\\theta)}{\\partial \\theta}=0\n$$\n\nMaximum likelihood estimators are often well-behaved with the following properties:\n\n-   (Asymptotically) unbiased\n\n-   Consistent\n\n-   Asymptotically best linear unbiased estimators (lowest variance among unbiased estimators)\n\n-   Asymptotically having normal distribution.\n\nThe last point is vital for inferences about estimands. One can see that these properties are often asymptotical, i.e. they should be considered with caution. But generally speaking, maximum likelihood estimators are usually the optimal way to go for medium to large samples and typically have good properties even for small sample sizes.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"LN10.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.353","editor":"visual","theme":"cosmo","title":"Point estimates","author":"Adam Cabla"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}