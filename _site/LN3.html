<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Adam Cabla">

<title>4ST621 - Characteristics of Random Variables</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">4ST621</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./Course_Intro.html" rel="" target="" aria-current="page">
 <span class="menu-text">Course Introduction</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./LN1.html">Probability Theory</a></li><li class="breadcrumb-item"><a href="./LN3.html">Characteristics of Random Variables</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Course_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Probability Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basics of Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Variable</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN3.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Characteristics of Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Vectors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Selected Discrete Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Selected Continuous Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Two Selected Multivariate Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stochastic convergences</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Mathematical Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Point estimates</span></a>
  </div>
</li>
          <li class="sidebar-item">
 <span class="menu-text">LN11.qmd</span>
  </li>
          <li class="sidebar-item">
 <span class="menu-text">LN12.qmd</span>
  </li>
          <li class="sidebar-item">
 <span class="menu-text">LN13.qmd</span>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#moments" id="toc-moments" class="nav-link" data-scroll-target="#moments">Moments</a>
  <ul class="collapse">
  <li><a href="#raw-moments" id="toc-raw-moments" class="nav-link" data-scroll-target="#raw-moments">Raw Moments</a></li>
  <li><a href="#central-moments" id="toc-central-moments" class="nav-link" data-scroll-target="#central-moments">Central Moments</a></li>
  <li><a href="#standardised-moments" id="toc-standardised-moments" class="nav-link" data-scroll-target="#standardised-moments">Standardised Moments</a></li>
  </ul></li>
  <li><a href="#characteristics-of-location" id="toc-characteristics-of-location" class="nav-link" data-scroll-target="#characteristics-of-location">Characteristics of Location</a>
  <ul class="collapse">
  <li><a href="#expected-value" id="toc-expected-value" class="nav-link" data-scroll-target="#expected-value">Expected Value</a></li>
  <li><a href="#median" id="toc-median" class="nav-link" data-scroll-target="#median">Median</a></li>
  <li><a href="#mode" id="toc-mode" class="nav-link" data-scroll-target="#mode">Mode</a></li>
  </ul></li>
  <li><a href="#characteristics-of-variability" id="toc-characteristics-of-variability" class="nav-link" data-scroll-target="#characteristics-of-variability">Characteristics of Variability</a>
  <ul class="collapse">
  <li><a href="#variance-and-standard-deviation" id="toc-variance-and-standard-deviation" class="nav-link" data-scroll-target="#variance-and-standard-deviation">Variance and standard deviation</a></li>
  <li><a href="#mean-absolute-deviation" id="toc-mean-absolute-deviation" class="nav-link" data-scroll-target="#mean-absolute-deviation">Mean Absolute Deviation</a></li>
  <li><a href="#inter-quartile-range" id="toc-inter-quartile-range" class="nav-link" data-scroll-target="#inter-quartile-range">Inter-quartile range</a></li>
  <li><a href="#entropy" id="toc-entropy" class="nav-link" data-scroll-target="#entropy">Entropy</a></li>
  </ul></li>
  <li><a href="#skewness" id="toc-skewness" class="nav-link" data-scroll-target="#skewness">Skewness</a></li>
  <li><a href="#kurtosis" id="toc-kurtosis" class="nav-link" data-scroll-target="#kurtosis">Kurtosis</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Characteristics of Random Variables</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Adam Cabla </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>In the previous chapter, random variables, which serve as probability models, were introduced together with how their probability distributions can be described. The functions used for this description give the full description, meaning no information is hidden, and any other information can be derived from this description.</p>
<p>What is this <em>other information</em>? Usually, we want to find meaningful shorthand descriptions of the properties of the random variable. These properties are typically called characteristics of random variables. Historically, four types of characteristics are of interest:</p>
<ul>
<li><p>Location</p></li>
<li><p>Variability</p></li>
<li><p>Skewness</p></li>
<li><p>Kurtosis</p></li>
</ul>
<p>For these types of characteristics, we can use various ways of characterisation; most commonly, we use quantiles - these were already introduced and moments to be introduced in a moment. There are, of course, various other possibilities, some of which will be discussed later.</p>
</section>
<section id="moments" class="level2">
<h2 class="anchored" data-anchor-id="moments">Moments</h2>
<section id="raw-moments" class="level3">
<h3 class="anchored" data-anchor-id="raw-moments">Raw Moments</h3>
<p>The moment is a concept known from ancient Greek physics, e.g.&nbsp;Archimedes on the centre of gravity of a lever: ‚Äú<em>A and B are equally balanced if their distances to the</em> <em>centre</em> <em>are inversely proportional to their weights.</em>‚Äù The centre of gravity is generally a point around which the resultant torque due to gravity forces vanishes; the object is in balance.</p>
<p>Let¬¥s imagine two persons weighing 60 and 80 kg swinging on a seesaw; the first is at point 0, and the second is at point 1. Where should the fulcrum be put so they can be balanced? According to Archimedes, their <em>distance to the centre should be inversely proportional to their weights</em>. So the first one should be at 8/14 of the distance to the centre, and the second one should be at 6/14 of the distance to the centre. The overall distance is 1, and the fulcrum should be at the point of 8/14. This point is the centre of gravity and the (first) moment.</p>
<p>Now, how can this point be calculated? Let¬¥s imagine a real line; values 0 and 1 represent points on this line, and weights are relative to the sum of all weights, so their sum is 1; the relative weight of the first person sitting at point 0 is <span class="math inline">\(60/(60+80)=6/14\)</span> and the relative weight of the second person sitting at point 1 is <span class="math inline">\(80/(60+80)=8/14\)</span>. The centre of gravity value can be calculated as <span class="math inline">\(0*6/14+1*8/14=8/14\)</span>.</p>
<p>Let¬¥s add the third person on the seesaw and put him at point 2 with a weight of 100 kg. So the relative weights are now 60/240 = 6/24, 8/24 and 10/24. See, their total is 1. The centre of gravity value can be calculated as <span class="math inline">\(0*6/24+1*8/24+2*10/24=28/24\approx{1.167}\)</span>. So, if you wanted to put a fulcrum below the seesaw for the line to be horizontal and stable, you would have to put it under the seesaw at this point.</p>
<p>This long introduction here tries to explain the (first raw) moment and why it is useful as a characteristic of the location. However, we derive various properties from three different types of moments and powers.</p>
<p>The first raw moment has been described so far, which, in probability theory, is also called expected value or simply expectation. We use values x as the points and probabilities P(x) as weights for discrete random variables. Because the sum of the <em>P</em>(<em>x</em>) equals 1, it is already relative weight. Similarly, we use the probability density function f(x) as the relative weight for continuous random variables. Still, since it is a continuous function, we must integrate instead of summing.</p>
<p><span class="math display">\[
E(X)=\sum_{x=-\infty}^{\infty}x*P(x)
\]</span></p>
<p><span class="math display">\[ E(X)=\int_{x=-\infty}^{\infty}x*f(x)dx \]</span></p>
<p>Now, the k-th raw moment is defined as the expected value of the <em>k</em>-th power of the random variable <em>X</em>:</p>
<p><span class="math display">\[ \mu_k^¬¥=E(X^k)= \sum_{x=-\infty}^{\infty}x^k*P(x) \]</span></p>
<p><span class="math display">\[ \mu_k^¬¥=E(X^k)=\int_{x=-\infty}^{\infty}x^k*f(x)dx \]</span></p>
</section>
<section id="central-moments" class="level3">
<h3 class="anchored" data-anchor-id="central-moments">Central Moments</h3>
<p>We can use central moments for some properties besides the raw moments. Centralisation is the term used to put the centre of the random variable to equal 0. This leads to the description of the random variable independent of its location.</p>
<p>We do this by subtracting the expected value from the values of the random variable: <span class="math inline">\(x-E(X)\)</span>. Now, the <em>k</em>-th central moment is defined as the expected value of the <em>k</em>-th power of the centralised random variable <em>X</em>:</p>
<p><span class="math display">\[ \mu_k=E((X-E(X))^k)= \sum_{x=-\infty}^{\infty}(x-E(X))^k*P(x) \]</span></p>
<p><span class="math display">\[ \mu_k=E((X-E(X))^k)=\int_{x=-\infty}^{\infty}(x-E(X))^k*f(x)dx \]</span></p>
</section>
<section id="standardised-moments" class="level3">
<h3 class="anchored" data-anchor-id="standardised-moments">Standardised Moments</h3>
<p>The last type of moment is the standardised (or normalised) moment. Proces of standardisation start with centralisation (to put the expected value equal to 0) and continues with dividing by the square root of the second central moment, which is called standard deviation. This ensures that a standardised random variable‚Äôs variance and standard deviation (moment measures of variability) equal 1, thus not influencing other properties we might desire to observe.</p>
<p>Now, the <em>k</em>-th standardised moment is defined as the expected value of the <em>k</em>-th power of the standardised random variable <em>X</em>:</p>
<p><span class="math display">\[ \alpha_k=E\left( \left( \frac{X-E(X)}{S.D.(X)} \right)^k \right)= \sum_{x=-\infty}^{\infty}
\left(\frac{x-E(X)}{S.D.(X)}\right)^k*P(x) \]</span></p>
<p><span class="math display">\[ \alpha_k=E\left( \left( \frac{X-E(X)}{S.D.(X)} \right)^k \right)= \int_{x=-\infty}^{\infty}
\left(\frac{x-E(X)}{S.D.(X)}\right)^k*f(x)dx \]</span></p>
</section>
</section>
<section id="characteristics-of-location" class="level2">
<h2 class="anchored" data-anchor-id="characteristics-of-location">Characteristics of Location</h2>
<p>Characteristics of location are an attempt to measure the center or typical value of the random variable. What would it be if we had to choose one number to represent the random variable?</p>
<section id="expected-value" class="level3">
<h3 class="anchored" data-anchor-id="expected-value">Expected Value</h3>
<p>The most commonly used characteristic of the location of a random variable is its expected value. This has already been introduced in the previous chapter; the expected value is the first raw moment - the centre of gravity, the point of balance of the mass represented by the probability function <em>P</em>(<em>x</em>) or probability density function <em>f</em>(<em>x</em>).</p>
<p><span class="math display">\[ \mu_1^¬¥=E(X)=\sum_{x=-\infty}^{\infty}x*P(x) \]</span></p>
<p><span class="math display">\[ \mu_1^¬¥=E(X)=\int_{x=-\infty}^{\infty}x*f(x)dx \]</span></p>
<p>The expected value has several important properties; for now, we stay with two of them:</p>
<ul>
<li><p>For real constant <em>c:</em> <span class="math inline">\(E(c)=c\)</span></p></li>
<li><p>Linearity of expectations, for real constants <em>a</em> and <em>c</em>: <span class="math inline">\(E(a+cX)=a+c*E(X)\)</span></p></li>
</ul>
</section>
<section id="median" class="level3">
<h3 class="anchored" data-anchor-id="median">Median</h3>
<p>The median has been mentioned in the chapter dealing with the quantile functions. Median x<sub>0.5</sub> is 50% quantile, which means it is a value satisfying the following equation</p>
<p><span class="math display">\[ F(x_{0.5})=P(X\leq{x_{0.5}})=0.5 \]</span></p>
<p><span class="math display">\[ x_{0.5}=Q(0.5)=F^{-1}(0.5) \]</span></p>
<p>In this course, for simplicity, we stay with the median as a characteristic used only for continuous random variables, so we can even specify</p>
<p><span class="math display">\[ F(x_{0.5})=P(X\leq{x_{0.5}})= \int_{-\infty}^{x_{0.5}}f(t)dt =0.5 \]</span></p>
<p>In simple terms, the median (for continuous random variable) is such a value for which half of the probability lies below this value and half above. It thus divides the distribution into two probabilistically equal halves.</p>
</section>
<section id="mode" class="level3">
<h3 class="anchored" data-anchor-id="mode">Mode</h3>
<p>Mode in the probability theory is the most probable value of a random variable. This holds for discrete random variables, while for continuous random variables, having no point probabilities, it is such value <em>x</em>, for which probability density function <em>f</em>(<em>x</em>) has a local maximum in the range of the random variable.</p>
<p>Probability distributions can be multimodal - having more than one mode (in the special case of two modes, it is called bimodal). As stated, modes are most commonly related to local maxima, so bimodal distribution can have two <em>peaks</em> in its probability density function without looking for the larger of the two maxima.</p>
<p>Apart from mode, distributions can have antimode(s); this term refers to the points <em>x</em>, for which the probability density function <em>f</em>(<em>x</em>) has its local minima. These points are not, however, considered characteristic of location.</p>
</section>
</section>
<section id="characteristics-of-variability" class="level2">
<h2 class="anchored" data-anchor-id="characteristics-of-variability">Characteristics of Variability</h2>
<p>Characteristics of variability are an attempt to measure the typical spread of the random variable. What would it be if we had to choose one number to represent a diversity of the probability distribution of the random variable?</p>
<section id="variance-and-standard-deviation" class="level3">
<h3 class="anchored" data-anchor-id="variance-and-standard-deviation">Variance and standard deviation</h3>
<p>The idea of the typical spread of the random variable starts simply by taking the centred random variable <span class="math inline">\(x-E(X)\)</span>. This random variable represents deviations of the values from its centre, represented by the expected value. So, it seems logical to find the typical deviation from the centre as another expected value:</p>
<p><span class="math display">\[E((x-E(X))^1)=\mu_1\]</span>This is the first central moment. The problem of this moment is that it is always 0. This comes straight ahead from the definition of the expected value being the centre of gravity - all points have ‚Äú<em>distances to the</em> <em>centre</em> <em>inversely proportional to their weights‚Äù.</em></p>
<p>There are several possible solutions to this problem, the most common one being to use the second power, hence the second central moment, which is in probability theory also called variance of the random variable:</p>
<p><span class="math display">\[ \mu_2=Var(X)=E((x-E(X))^2)=\sum_{x=-\infty}^{\infty}(x-E(X))^2*P(x) \]</span></p>
<p><span class="math display">\[ \mu_2=Var(X)=E((x-E(X))^2)=\int_{x=-\infty}^{\infty}(x-E(X))^2*f(x)dx \]</span></p>
<p>This form is called definitional; for evaluation of variance, it might be useful to use a so-called computational form of variance:</p>
<p><span class="math display">\[Var(X)=E(X^2)-[E(X)]^2\]</span>Variance can be calculated as the second raw moment minus the second power of the first raw moment. In other words, as the expected value of the squared random variable minus the square of the expected value of the random variable.</p>
<p>Some important properties of the variance are:</p>
<ul>
<li><p>Non-negativity <span class="math inline">\(Var(X)\geq{0}\)</span></p></li>
<li><p>Constant (real value <em>c</em>) has zero variance <span class="math inline">\(Var(c)=0\)</span></p></li>
<li><p>For real constants <em>a</em> and <em>c:</em> <span class="math inline">\(Var(a+cX)=c^2Var(X)\)</span></p></li>
</ul>
<p>So, the variance is the expected squared deviation from the expected value. The trouble with this definition is that variance is measured in the squared units of the random variable. Imagine a random variable being, e.g.&nbsp;height measured in <em>cm</em>, then the variance of the height would be measured in <em>cm</em><sup>2</sup>.</p>
<p>From a descriptive point of view, it is more useful to use standard deviation, which is the squared value of variance. This measures a <em>typical deviation</em> in the original units of the random variable but does not have a simple explanation of the meaning. Mathematically, we might refer to the standard deviation as an expected quadratic deviation from the expected value.</p>
<p><span class="math display">\[ S.D.(X)=\sqrt{Var(X)} \]</span></p>
</section>
<section id="mean-absolute-deviation" class="level3">
<h3 class="anchored" data-anchor-id="mean-absolute-deviation">Mean Absolute Deviation</h3>
<p>Another possibility to deal with the problem that the first central moment is equal to 0 is to use absolute deviations instead of squared deviations:</p>
<p><span class="math display">\[ MAD(X)=E(|x-E(X)|)=\sum_{x=-\infty}^{\infty}|x-E(X)|*P(x) \]</span></p>
<p><span class="math display">\[ MAD(X)=E(|x-E(X)|)=\int_{x=-\infty}^{\infty}|x-E(X)|*f(x)dx \]</span></p>
<p>In probability theory, mean absolute deviation most commonly refers to the deviation from the expected value. This way of measuring variability is a more <em>common sense typical deviation</em> in the probability distribution than standard deviation.</p>
<p>Still, there are two main reasons why the standard deviation is more commonly used; first, it is tightly connected to the normal distribution, which belongs among the most important probability distributions for reasons we will get into later; second, it has one important connection to the expected value.</p>
<section id="intermezzo" class="level4">
<h4 class="anchored" data-anchor-id="intermezzo">Intermezzo</h4>
<p>If we were looking for the real-valued constant <em>c,</em> for which the probability-weighted sum of squared deviations from such a constant ‚àëùë•=‚àí‚àû‚àû(ùë•‚àíùëê)2‚àóùëÉ(ùë•) is minimal, then it would be the <span class="math inline">\(c=E(X)\)</span>. So, the variance is minimised if we use the expected value as the location characteristic. This has far-reaching consequences, e.g.&nbsp;for linear regression, in which conditional expected values are modelled by a linear combination of variables and the <em>optimal</em> constants in the model are found by minimising residual variance. But do not get disturbed too much here with thoughts of linear regression; it is not the scope of this course.</p>
</section>
<section id="back-to-mad" class="level4">
<h4 class="anchored" data-anchor-id="back-to-mad">Back to MAD</h4>
<p>Using the same logic as in the intermezzo, what real-valued constant c would minimise the probability-weighted sum of absolute deviations <span class="math inline">\(\sum_{x=-\infty}^\infty |x-c|*P(x)\)</span>? Maybe surprisingly, the constant is not the expected value in this case, but median <span class="math inline">\(c=x_{0.5}\)</span>.</p>
<p>So, using the same logic, in which the expected value is connected to the variance, the mean absolute deviation should be connected to the median. And by the same reasoning, when modelling conditional medians by a linear combination of variables, the <em>optimal</em> constants are found by minimising residual mean absolute deviations. This type of modelling is called median (or, more generally, quantile) regression. Again, do not get disturbed by this.</p>
<p>So, do we use expected value or median when calculating mean absolute deviation? Well, both can and are being used under the same acronym. Even the median absolute deviation shares the same acronym, MAD. Does it make your head hurt? Sorry, no one promised you it would always be easy.</p>
<p>In this course, we will use the expected value to measure location when calculating mean absolute deviation, so we will follow the formulas at the beginning of this sub-chapter.</p>
</section>
</section>
<section id="inter-quartile-range" class="level3">
<h3 class="anchored" data-anchor-id="inter-quartile-range">Inter-quartile range</h3>
<p>Apart from measuring variability by a moment-based approach, we can also use a quantile-based approach. We can measure ranges between pre-specified quantiles and use them to measure variability with probabilistic meaning. The one that we will stick to within the course is the inter-quartile range</p>
<p><span class="math display">\[ IQR(X)=x_{0.75}-x_{0.25} \]</span></p>
<p>The inter-quartile range is the range (distance) needed to capture the middle 50 % of the probability distribution.</p>
</section>
<section id="entropy" class="level3">
<h3 class="anchored" data-anchor-id="entropy">Entropy</h3>
<p>The last characteristic to be introduced as a measure of variability comes from the information theory. Entropy measures the random variable‚Äôs <em>expected ability to surprise</em> or <em>information content</em>.</p>
<p>It starts with a negative logarithmic transformation of probability <span class="math inline">\(-log_b(P(x))\)</span>. Value with probability 0 can be viewed as impossible or <em>infinitely</em> <em>surprising,</em> and indeed <span class="math inline">\(-log_b(0)=Inf\)</span>. On the second part of the scale, a value with probability 1 is sure to happen or <em>totally unsurprising</em> and indeed <span class="math inline">\(-log_b(1)=0\)</span>. So, the initial transformation gives us the potential measure of <em>surprisingness,</em> and entropy measures the expected value of this</p>
<p><span class="math display">\[ H(X)=E(-log_b(P(x)))=\sum_{x=-\infty}^{\infty}P(x)*-log_b(P(x)) \]</span></p>
<p>Notice that the introduced entropy measure is based on the probabilities and is suitable for only discrete random variables. The trouble with continuous random variables is that ùëì(ùë•)‚â•0, and if the probability density value is above 1, the logarithm is positive, and entropy can be negative. So, we will skip the problem of measuring the entropy of continuous random variables and use it only as a measure for discrete random variables.</p>
<p>Now, what units is entropy measured in? It depends on the base of the logarithm - <em>b</em>. The most common base, the one used in this course, is 2. Then, entropy is measured in <em>bits</em>. However, other bases can be used, e.g., base 10 leads to units called <em>dits,</em> or base <em>e</em> leads to units called <em>nats</em>.</p>
<p>The little trouble with entropy is, that its value depends on the number of possible values <em>x</em> of random variable. Maximum entropy can be achieved if all the values of the random variable are equally likely (so-called discrete uniform distribution).</p>
<p>Assume there are <em>k</em> possible values, each with probability <span class="math inline">\(P(x)=\frac{1}{k}\)</span>, then maximal entropy is</p>
<p><span class="math display">\[
H(X)=-\sum_{x=- \infty}^{\infty}P(x)*log_b P(x)=-k*\frac{1}{k}*log_b \frac {1}{k}=log_b(k)
\]</span></p>
<p>So for comparison among random variables with different numbers of possible values of random variable (<em>k</em>)<em>,</em> normalised entropy, called efficiency, can be used</p>
<p><span class="math display">\[ \eta(X)=\frac{H(X)}{log_b(k)} \]</span></p>
</section>
</section>
<section id="skewness" class="level2">
<h2 class="anchored" data-anchor-id="skewness">Skewness</h2>
<p>Apart from the location and variability of the random variables, we might be interested in other characteristics. The two most common among these are skewness and kurtosis, and the most common way of measuring them is based on standardised moments. These were already introduced, so to repeat, these are moments based on the <em>k</em>-th powers of standardised random variables, where the standardisation leads to the same expected value 0 and the same variance 1, thus effectively eliminating them from the evaluation of the shape of the distribution.</p>
<p>Moment measure of skewness is the 3rd standardised moment</p>
<p><span class="math display">\[ \alpha_3=E\left( \left( \frac{X-E(X)}{S.D.(X)} \right)^3 \right)= \sum_{x=-\infty}^{\infty} \left(\frac{x-E(X)}{S.D.(X)}\right)^3*P(x) \]</span></p>
<p><span class="math display">\[ \alpha_3=E\left( \left( \frac{X-E(X)}{S.D.(X)} \right)^3 \right)= \int_{x=-\infty}^{\infty} \left(\frac{x-E(X)}{S.D.(X)}\right)^3*f(x)dx \]</span></p>
<p>Operationally, we can distinguish the skewness or the <em>lean</em> of the distribution into three possibilities:</p>
<ul>
<li><p>Positive skewness - distribution is skewed towards the right, so the larger part of the mass is on the left.</p></li>
<li><p>Null skewness - distribution is symmetric.</p></li>
<li><p>Negative skewness - distribution is skewed towards the left, so the larger part of the mass is on the right.</p></li>
</ul>
</section>
<section id="kurtosis" class="level2">
<h2 class="anchored" data-anchor-id="kurtosis">Kurtosis</h2>
<p>The moment measure of kurtosis is the 4th standardised moment</p>
<p><span class="math display">\[ \alpha_3=E\left( \left( \frac{X-E(X)}{S.D.(X)} \right)^3 \right)= \sum_{x=-\infty}^{\infty} \left(\frac{x-E(X)}{S.D.(X)}\right)^3*P(x) \]</span></p>
<p><span class="math display">\[ \alpha_3=E\left( \left( \frac{X-E(X)}{S.D.(X)} \right)^3 \right)= \int_{x=-\infty}^{\infty} \left(\frac{x-E(X)}{S.D.(X)}\right)^3*f(x)dx \]</span></p>
<p>While skewness is a somewhat self-explanatory term, kurtosis is not well known. Historically, kurtosis was viewed as a measure of centralisation - the larger the mass is in the centre, the larger the kurtosis should be. But, nowadays, the prevailing view is that kurtosis is a measure of the heaviness of the tails - the larger the mass is in the tails, the larger the kurtosis is.</p>
<p>Does it make sense? At first sight, having a larger mass in the centre and the tails is contradictory, but it is true in many probability distributions. What is lacking in these distributions is the mass somewhere in between the centre and the tails.</p>
<p>Operationally, we can distinguish the kurtosis into three possibilities by comparing it to the kurtosis of the normal distribution, which is equal to 3:</p>
<ul>
<li><p>Leptokurtic: <span class="math inline">\(\alpha_4&gt;3\)</span></p></li>
<li><p>Mesokurtic: <span class="math inline">\(\alpha_4=3\)</span></p></li>
<li><p>Platykurtic: <span class="math inline">\(\alpha_4&lt;3\)</span></p></li>
</ul>
<p>Due to the direct comparability to the normal distribution kurtosis, the excess kurtosis ùõº<sub>4</sub>‚àí3 is sometimes used.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>