<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Adam Cabla">

<title>4ST621 - Selected Discrete Distributions</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">4ST621</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./Course_Intro.html" rel="" target="" aria-current="page">
 <span class="menu-text">Course Introduction</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./LN1.html">Probability Theory</a></li><li class="breadcrumb-item"><a href="./LN5.html">Selected Discrete Distributions</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Course_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Probability Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basics of Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Variable</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Characteristics of Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Vectors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN5.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Selected Discrete Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Selected Continuous Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Two Selected Multivariate Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stochastic convergences</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Mathematical Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Point estimates</span></a>
  </div>
</li>
          <li class="sidebar-item">
 <span class="menu-text">LN11.qmd</span>
  </li>
          <li class="sidebar-item">
 <span class="menu-text">LN12.qmd</span>
  </li>
          <li class="sidebar-item">
 <span class="menu-text">LN13.qmd</span>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#bernoulli-distribution-xsim-bepi" id="toc-bernoulli-distribution-xsim-bepi" class="nav-link" data-scroll-target="#bernoulli-distribution-xsim-bepi">Bernoulli distribution <span class="math inline">\(X\sim Be(\pi)\)</span></a></li>
  <li><a href="#binomial-distribution-x-sim-binpi" id="toc-binomial-distribution-x-sim-binpi" class="nav-link" data-scroll-target="#binomial-distribution-x-sim-binpi">Binomial distribution <span class="math inline">\(X \sim Bi(n,\pi)\)</span></a></li>
  <li><a href="#hypergeometric-distribution-x-sim-hgnkn" id="toc-hypergeometric-distribution-x-sim-hgnkn" class="nav-link" data-scroll-target="#hypergeometric-distribution-x-sim-hgnkn">Hypergeometric distribution <span class="math inline">\(X \sim Hg(N,K,n)\)</span></a></li>
  <li><a href="#poisson-distribution-x-sim-polambda" id="toc-poisson-distribution-x-sim-polambda" class="nav-link" data-scroll-target="#poisson-distribution-x-sim-polambda">Poisson distribution <span class="math inline">\(X \sim Po(\lambda)\)</span></a>
  <ul class="collapse">
  <li><a href="#detour-convergence-hgto-bito-po" id="toc-detour-convergence-hgto-bito-po" class="nav-link" data-scroll-target="#detour-convergence-hgto-bito-po">Detour: convergence <span class="math inline">\(Hg\to Bi\to Po\)</span></a></li>
  </ul></li>
  <li><a href="#geometric-distribution-xsim-gepi" id="toc-geometric-distribution-xsim-gepi" class="nav-link" data-scroll-target="#geometric-distribution-xsim-gepi">Geometric distribution <span class="math inline">\(X\sim Ge(\pi)\)</span></a></li>
  <li><a href="#negative-binomial-distribution-x-sim-nbirpi" id="toc-negative-binomial-distribution-x-sim-nbirpi" class="nav-link" data-scroll-target="#negative-binomial-distribution-x-sim-nbirpi">Negative binomial distribution <span class="math inline">\(X \sim NBi(r,\pi)\)</span></a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Selected Discrete Distributions</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Adam Cabla </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Random Variables might be viewed as simple possible data-generating models. We have already introduced them as such and looked at the ways to describe their probability distributions and characteristics.</p>
<p>Many of these models might be generalised under specific conditions. Given some assumptions about the data-generating process, a particular probability distribution might arise. Because some of these assumptions are legitimate and repeated often, we give the names to the arising probability distributions.</p>
<p>Usually, one of the assumptions is some quantifiable property, which then enters the probability distribution as a so-called parameter; from the other side, the parameter is a numerical constant driving specific shape distribution.</p>
<p>In this part, we will focus on some named discrete probability distributions; in the later part, we will look at some named continuous probability distributions.</p>
<p>We will focus on expected value and variance to characterise these probability distributions.</p>
</section>
<section id="bernoulli-distribution-xsim-bepi" class="level2">
<h2 class="anchored" data-anchor-id="bernoulli-distribution-xsim-bepi">Bernoulli distribution <span class="math inline">\(X\sim Be(\pi)\)</span></h2>
<p>Let´s begin with the simplest probability distribution. In this probability distribution, we assume one random trial ends by observing a specific random event of interest (often called <em>success)</em> or not. Such a random trial, which can end up with two different possible outcomes, is called Bernoulli´s trial after Swiss mathematician Jacob Bernoulli. As we will later see, the name connected to the first descriptions of probabilistic convergences and the discovery of Euler´s constant <em>e</em>.</p>
<p>The probability of observing this random event of success is usually denoted as <em>p</em> or <span class="math inline">\(\pi\)</span>. We will stick to the later notation in this course. Because this is the numerical constant that drives the specific shape of the distribution, it is a parameter of Bernoulli’s random variable.</p>
<p>The random variable is thus a random variable describing the probability distribution of a single Bernoulli trial. The probability of success is 𝜋, and the probability of failure is <span class="math inline">\(1-\pi\)</span>. Putting <em>success</em> = 1 and <em>failure</em> = 0, we can write the probability function:</p>
<p><span class="math display">\[
P(x)=\pi^x(1-\pi)^{1-x}
\]</span> for <span class="math inline">\(x\in \{0;1\}\)</span> and <span class="math inline">\(\pi\in[0;1]\)</span>.</p>
<p>Expected value and variance can be derived quite simply:</p>
<p><span class="math display">\[
E(X)=\sum_{x=0}^1x*P(x)=0*\pi^0*(1-\pi)^{0-0}+1*\pi^1*(1-\pi)^{1-0}=\pi
\]</span> <span class="math display">\[
E(X^2)=\sum_{x=0}^1x^2*P(x)=0^2*\pi^0*(1-\pi)^{0-0}+1^2*\pi^1*(1-\pi)^{1-0}=\pi
\]</span></p>
<p><span class="math display">\[Var(X)=E(X^2)-[E(X)]^2=\pi-\pi^2=\pi(1-\pi)\]</span>While for now, the Bernoulli distribution might seem a little dull and uninteresting, it has a prominent place in the probability theory and statistical modelling because it represents a model for the probability itself.</p>
</section>
<section id="binomial-distribution-x-sim-binpi" class="level2">
<h2 class="anchored" data-anchor-id="binomial-distribution-x-sim-binpi">Binomial distribution <span class="math inline">\(X \sim Bi(n,\pi)\)</span></h2>
<p>The binomial distribution is an extension of the Bernoulli distribution. It starts with the Bernoulli trial (two possible outcomes; success (1) has probability <span class="math inline">\(\pi\)</span>), but now we have <em>n</em> independentBernoulli trials. The random variable is the number of <em>successes</em> in those trials.</p>
<p>The probability function of the Binomial distribution is</p>
<p><span class="math display">\[
P(x)={n\choose{x}}\pi^x(1-\pi)^{n-x}
\]</span></p>
<p>for <span class="math inline">\(x=0,1,...,n\)</span>; <span class="math inline">\(\pi\in[0;1]\)</span> and <span class="math inline">\(n\in \{0,1,2,...\}\)</span></p>
<p>The idea behind this probability function goes like this: first, think of the probability of one specific sequence of <em>failures</em> and <em>successes,</em> e.g.&nbsp;{0, 0, 0, 1, 1}. The probability of this sequence is <span class="math inline">\((1-\pi)*(1-\pi)*(1-\pi)*\pi*\pi=\pi^2(1-\pi)^3\)</span>.</p>
<p>A more general question is the probability of observing two successes no matter the specific order. There are more possible sequences, each with the same probability. Overall probability is the sum of these probabilities. Hence, we multiply the probability of a sequence by the number of possible sequences, which is given by the binomial coefficient <span class="math inline">\(n\choose{x}\)</span>.</p>
<p>Expected value and variance are</p>
<p><span class="math display">\[
E(X)=n\pi
\]</span></p>
<p><span class="math display">\[
Var(X)=n\pi(1-\pi)
\]</span></p>
<p>Binomial distribution might be more formally defined as the summation of <em>n</em> Bernoulli distributions:</p>
<p><span class="math display">\[
Y\sim Be(\pi)\to X=\sum_{i=1}^{n}Y_i \sim Bi(n,\pi)
\]</span>From the other side, Bernoulli distribution might be viewed as a specific case of the binomial distribution for <em>n</em> = 1.</p>
</section>
<section id="hypergeometric-distribution-x-sim-hgnkn" class="level2">
<h2 class="anchored" data-anchor-id="hypergeometric-distribution-x-sim-hgnkn">Hypergeometric distribution <span class="math inline">\(X \sim Hg(N,K,n)\)</span></h2>
<p>The binomial distribution represents a number of <em>successes</em> in a series of independent Bernoulli trials with the constant probability <span class="math inline">\(\pi\)</span> of <em>success</em> in one trial. One process that leads to the Bernoulli trials is random sampling <em>with replacement</em>. In this specific sampling, a unit is sampled from the population and then returned so it can be sampled again later.</p>
<p>In the setup of sampling from the population, a more common type is sampling <em>without replacement</em>. This means that once a unit is sampled from the population, it is NOT returned and hence cannot be sampled again. Think about sampling <em>at once</em>. In this type of sampling, the probability of <em>success</em> changes at each sampling step, violating the binomial distribution assumption.</p>
<p>We can use hypergeometric distribution if we want to find out the probability distribution of the number of successes in the random sampling without replacement from the finite population. The information needed is the sample size <em>n</em>, population size <em>N</em>, and number of <em>successes</em> in the population <em>K</em>. Probability function is</p>
<p><span class="math display">\[
P(x)=\frac {\binom{K}{x} \binom{N-K}{n-x}}{\binom{N}{n}}
\]</span></p>
<p>for <span class="math inline">\(x=\{max(0,n+K-N),...,min(n,K) \}\)</span>; <span class="math inline">\(N\in\{0, 1, 2,...\}\)</span>, <span class="math inline">\(K\in\{0, 1, 2, ..., N \}\)</span>, and <span class="math inline">\(n\in \{0, 1, 2, ..., N \}\)</span>.</p>
<p>The idea behind this probability function is to calculate the number of all possible samples with <em>x successes</em> and divide it by the number of all possible samples. Assuming that sampling is random, each possible sample has the same probability, and the classical definition of probability applies. Characteristics follow</p>
<p><span class="math display">\[
E(X)=\frac{K}{N}
\]</span></p>
<p><span class="math display">\[
Var(X)=n\frac{K}{N}\left(1-\frac{K}{N}\right)\frac{N-n}{N-1}
\]</span></p>
<p>In the characteristics, we can see a resemblance to the binomial distribution. If we imagine sampling, starting at the first step, the probability of <em>success</em> is the same: <span class="math inline">\(\pi=\frac{K}{N}\)</span>. The expected value is the same for both sampling schemes - with or without replacement. But variance is different by the last fraction <span class="math inline">\(\frac{N-n}{N-1}\)</span>. This fraction is called finite population correction.</p>
<p>One can also notice that the variance is the same for the sample size n = 1. That is because, with this sampling size, we talk about the Bernoulli distribution.</p>
</section>
<section id="poisson-distribution-x-sim-polambda" class="level2">
<h2 class="anchored" data-anchor-id="poisson-distribution-x-sim-polambda">Poisson distribution <span class="math inline">\(X \sim Po(\lambda)\)</span></h2>
<p>With this distribution, we are still looking for a number of <em>successes</em> but call it now <em>events.</em> We will assume that those successes are occurring throughout specified intervals randomly and independently of each other with a constant rate of occurrence. This happens mostly in the time domain, but intervals can represent something else, e.g.&nbsp;distance. Under the mentioned assumption, the number of <em>events</em> follows the probability function.</p>
<p><span class="math display">\[
P(x)=e^{-\lambda}\frac{\lambda^x}{x!}
\]</span></p>
<p>for <span class="math inline">\(x\in\{0, 1, 2, ...\}\)</span> and <span class="math inline">\(\lambda \in (0;\infty)\)</span>.</p>
<p>Characteristics are</p>
<p><span class="math display">\[
E(X)=\lambda
\]</span></p>
<p><span class="math display">\[
Var(X)=\lambda
\]</span></p>
<p>Parameter <span class="math inline">\(\lambda\)</span> is called a rate parameter; it defines the expected number of <em>events</em> in a given interval. <span class="math inline">\(\lambda\)</span> is always connected to the interval’s length and responds to it one-to-one. E.g. if the rate is five <em>events</em> per hour, but we are interested in the number of events per day, we use <span class="math inline">\(\lambda=24*5=120\)</span>.</p>
<section id="detour-convergence-hgto-bito-po" class="level3">
<h3 class="anchored" data-anchor-id="detour-convergence-hgto-bito-po">Detour: convergence <span class="math inline">\(Hg\to Bi\to Po\)</span></h3>
<p>The three introduced distributions are tightly connected, and a possible order of approximations goes from the computationally most complex (relying on the largest number of parameters) to the least complex. However, there is no free lunch - approximations are not exact results, so we trade the result’s precision with the complexity of calculations; less obviously, we trade parameters for the assumptions.</p>
<p>Hypergeometric distribution can be approximated by binomial distribution if the ratio between sample and population sizes is small enough (the smaller, the better). With this ratio being small, there is only a small difference between sampling with and without replacement. Usually, the boundary for the approximation given is <span class="math inline">\(n/N&lt;0.1\)</span></p>
<p><span class="math display">\[
Hg(N,K,n)\xrightarrow {n/N\to0} Bi\left(n,\pi=\frac{K}{N}\right)
\]</span></p>
<p>Similarly, binomial distribution can be approximated by the Poisson distribution if the number of Bernoulli trials is high enough and the probability of <em>success</em> is low enough. In this case, we stop thinking in a sequence of Bernoulli trials and start thinking about the whole sequence as one interval long enough. The boundaries for the approximation are usually in the literature given as <span class="math inline">\(n&gt;30,\pi&lt;0.1\)</span>.</p>
<p><span class="math display">\[
Bi(n,\pi)\xrightarrow{n \to \infty,\pi \to 0}Po(\lambda=n\pi)
\]</span></p>
<p>With these approximations, expectations remain the same. Still, the shape of the probability distribution is changing, and variance is increasing, leading to overestimated probability in the tails and underestimated probability in the centre of the distribution.</p>
<p><span class="math display">\[
E(X)=n\frac{K}{N}=n\pi=\lambda
\]</span></p>
<p><span class="math display">\[
Var(X)=n\frac{K}{N}\left(1-\frac{K}{N} \right)\frac{N-n}{N-1}&lt;n\pi(1-\pi)&lt;\lambda
\]</span></p>
</section>
</section>
<section id="geometric-distribution-xsim-gepi" class="level2">
<h2 class="anchored" data-anchor-id="geometric-distribution-xsim-gepi">Geometric distribution <span class="math inline">\(X\sim Ge(\pi)\)</span></h2>
<p>Let´s return to the Bernoulli trials. But now, our interest is in the number of <em>failures</em> before observing the first <em>success.</em> This random variable follows a geometric distribution with the probability function.</p>
<p><span class="math display">\[
P(x)=\pi*(1-\pi)^x
\]</span></p>
<p>for <span class="math inline">\(x\in\{0,1,2,... \}\)</span> and <span class="math inline">\(\pi\in [0;1]\)</span></p>
<p>This probability function has a straightforward meaning: what is the probability of observing a sequence <span class="math inline">\(\{ 0,0,...,1 \}\)</span>, where the number of 0s is the value of the random variable <em>x</em>.</p>
<p>Characteristics are</p>
<p><span class="math display">\[
E(X)=\frac{\ 1 - \pi}{\pi}
\]</span></p>
<p><span class="math display">\[
Var(X)=\frac{1-\pi}{\pi^2}
\]</span></p>
<p>This probability distribution can be connected to the binomial distribution. Using the same parameter <span class="math inline">\(\pi\)</span>, we can see that the number of trials in the binomial distribution is,<span class="math inline">\(n=x_{ge}\)</span> and the <span class="math inline">\(x_{bi}=0\)</span> will give us the probability of observing 0 <em>successes</em> in a sequence. This has to be multiplied by one probability of <em>success</em> to have the end of the sequence equal 1. Imagine we want to see five failures before the first success in geometric distribution:</p>
<p><span class="math display">\[
X_{ge} \sim Ge(\pi) \to P(X_{ge}=5)=\pi*(1-\pi)^5
\]</span></p>
<p>Using binomial distribution:</p>
<p><span class="math display">\[
X_{bi} \sim Bi(n=x_{ge}=5;\pi) \to \pi*P(0)=\pi* \binom{5}{0}\pi^0(1-\pi)^{5-0}=\pi*(1-\pi)^5
\]</span></p>
</section>
<section id="negative-binomial-distribution-x-sim-nbirpi" class="level2">
<h2 class="anchored" data-anchor-id="negative-binomial-distribution-x-sim-nbirpi">Negative binomial distribution <span class="math inline">\(X \sim NBi(r,\pi)\)</span></h2>
<p>Similarly, as we generalised from the Bernoulli to the binomial distribution, we can generalise from the geometric distribution to the negative binomial distribution. Having a probability of <em>success</em> <span class="math inline">\(\pi\)</span><em>,</em> we are interested in the number of failures before the <em>r</em>-th <em>success</em>.</p>
<p>The probability function has a very similar construction to the one from the binomial distribution - the probability of one sequence, e.g.&nbsp;<span class="math inline">\(\{0, 0, 0,0,1,1 \}\)</span> is <span class="math inline">\(\pi^2*(1-\pi)^3\)</span>. The sequence has to end with <em>success</em> because that´s what we are waiting for. However, more than one sequence has two <em>successes</em> and ends with one (of those two), specifically <span class="math inline">\(\binom{4}{1}\)</span>, because the last position is given, and we combine one <em>success</em> in 4 positions. All these sequences will have the same probability; the overall probability is the summation of these, which means <span class="math inline">\(\binom{4}{1}\pi^2(1-\pi)^4\)</span>.</p>
<p>Generalising this thought process, wanting to have <em>r successes</em>, we can write probability function as</p>
<p><span class="math display">\[
P(x)=\binom{x+r-1}{x}\pi^r(1-\pi)^x
\]</span></p>
<p>Characteristics are</p>
<p><span class="math display">\[
E(x)=r\frac{1-\pi}{\pi}
\]</span></p>
<p><span class="math display">\[
Var(X)=r\frac{1-\pi}{\pi^2}
\]</span></p>
<p>A negative binomial distribution might be formally defined as a summation of the geometric distributions, the same way the summation of Bernoulli distributions led to a binomial.</p>
<p><span class="math display">\[
Y\sim Ge(\pi)\to X=\sum_{i=1}^{r}Y_i \sim NBi(r,\pi)
\]</span></p>
<p>A geometric distribution might be considered a special negative binomial case.</p>
<p>The last relation in this part is the one between binomial and negative binomial distributions. From the example looking for the probability of observing the second <em>success</em> after the third <em>failure</em>, we can translate it to the binomial distribution: ignore the last position of a sequence, which is always given as <em>success</em>, then <span class="math inline">\(\pi\)</span> is shared, the number of trials is the number of <em>failures</em> and <em>successes</em> minus one, <span class="math inline">\(n=x_{NBi}+r-1\)</span> and we are looking for the probability of <span class="math inline">\(x_{Bi}=r-1\)</span>. The last step is multiplying the result by the last position, hence the probability of <em>success</em> <span class="math inline">\(\pi\)</span>.</p>
<p><span class="math display">\[
X_{Bi} \sim Bi(n=r+x_{NBi}-1=4,\pi)\to \pi*P(r-1=1)= \binom{4}{1}\pi^2(1-\pi)^3
\]</span></p>
<p>The only distinction from the formula for a negative binomial distribution is in binomial coefficient, but they are always equal</p>
<p><span class="math display">\[
\binom{4}{1}=\frac{4!}{1!3!}=\binom{4}{3}
\]</span></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>