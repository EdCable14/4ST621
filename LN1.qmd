---
title: "Basics of Probability"
author: "Adam Cabla"
---

## Interpretation of Probability

Let´s begin with the interpretation of probability -- what does probability *mean*?

What does it mean when someone says the "probability of dying at 80 is 0.03"?

What does it mean when someone says the "probability of tomorrow's rain is 0.5"?

There must be some meaning. Throughout history, two competing schools of probability thought have always existed. One is known as **objectivist**, and the second is known as **subjectivist.**

For the first school, the one that dominates this course, probability is an object that we might attempt to discover, but something that exists no matter what we do. Historically, this school has been presented as a physical school, which describes probability as the result of the world's physics. In a more modern setting, this school is presented more as frequentist, which holds that probability is a limit of relative frequency in a repeated series of random trials.

For the second school, the one that has been somewhat suppressed in the 20th century but is on the rise recently, probability is a subject -- something that is dependent on the observer. In this school of thought, the probability is an expression of uncertainty.

While this distinction might, for you, now seem a somewhat interesting but useless philosophical quarrel, it eventually leads to two surprisingly different ways of doing statistical inference, which is in scope in the second half of the course.

## Definitions of Probability

In the previous part, the focus was on the interpretation of probability. Let´s now discuss the definition of probability. These are hard to separate from the interpretation and, in some cases, are tightly connected.

### The classical definition of probability

Historically, formal treatises on probabilities emerged in the 16^th^ and 17^th^ centuries with scholars dealing with the "game of chance". These games were based chiefly on throwing dice, but others were also based on cards or roulette wheels. With these games, the idea of a *fair outcome* emerged -- that each outcome at one random trial has equivalent probability. With this assumption, it was easy to calculate probabilities by counts and combinatorics theory, which was emerging to solve many probabilistic puzzles.

What emerged in the works of Italian Gerolamo Cardano is now called **classical definition** and was cemented by Pierre-Simon Laplace. It states that the probability of an event is the ratio of favourable outcomes to all possible outcomes with the principle of difference -- no specific outcome is more likely than any other.

#### Intermezzo - Important Terms

**Random trial --**a trial (experiment) in which results cannot be predicted with certainty and repeatable (at least theoretically) under the same conditions.

**Random event** -- is a result of **random trial**.

**Elementary random event** -- is *the smallest possible outcome* of a random trial. More formally, it is such a random event that the union of other random events cannot create it. Is indivisible.

**Sample space E** -- is a set of all possible elementary random events.

**Random events** (usually denoted by capital letters from the beginning of the alphabet -- A, B, C,...)can thus be viewed as any non-empty subset of sample space.

**Set operations** are essential for probability calculations because the definitions of the initial terms are based on the sets.

**Intersection** $A \cap B$ is a set operation, meaning both A and B are *true*.

**Union** $A \cup B$ is a set operation, meaning at least one of A and B is *true.*

**Complement** $\bar A$ is a set operation meaning *true if A is not true*. Opposite of A.

#### Going back to the classical definition of probability

With new terms, we can define the classical definition of probability as

$$ P(A)= \frac {m}{n} $$

Where *A* is the union of *m* (number of favourable) random events and *n* is the number of all possible random events, where individual events are equally likely and mutually exclusive.

### Geometric definition of probability

The classical definition of probability was, among other things, limited by its discrete nature. To overcome this limitation and solve new issuing problems, scholars in the 18th century started thinking about continuous sample spaces. This led to the generalisation called the geometric definition of probability, which can be expressed as

$$ P(A)=\frac {V(A)}{V(E)} $$

The V operator represents continuous measure -- in one dimension length, in two dimensions area and in more dimensions simply volume. What remained was the idea that each pair of regions of the same volume was equally likely.

The most famous problem solved using the geometric definition of probability was Buffon´s needle: Imagine a floor made of parallel strips of wood, each with the same width *t*. Now, randomly drop a needle with a length of l onto this floor. How likely is the needle to lie across a line between two strips? This probability, assuming $l \leq t$, was proved to be

$$ P(A)=\frac {2*l}{\pi*t} $$

Much later, this problem was turned around, and Buffon´s needle was used to estimate the value of $π$ by substituting relative frequency *p* for probability P(A):

$$ est(\pi)=\frac{2*l} {p *t} $$

Substituting relative frequency for probability is a trick available thanks to the laws describing convergences in probability and is the basis of the frequentist definition.

### Frequentist definition of probability

The classical definition of probability stumbled upon a severe limitation -- its reliance on the principle of indifference, which might be justifiable in the games of chance but hardly so in other real-world instances. This led to more broad definition of probability.

Have a series of random trials. Based on this series, we have a series of relative frequencies of observing random event A: p~n~(A). This series of relative frequencies will converge (in probability) to its limit, the underlying probability of an event A.

$$p_n(A) \rightarrow P(A)$$We will deal with stochastic convergences later because these laws connect probability theory with statistics.

### Axiomatic definition

Around the same time R.A. Fischer or Richard von Misses (brother of not less famous Austrian economist Ludwig von Misses) were championing and rigorously proving frequentist definition and interpretation of probability, a completely new approach emerged: axiomatic definition, work of brilliant Russian mathematician A. N. Kolmogorov. This approach focused on the smallest basic set of rules, axioms, which can serve as a basis for all manipulations with probabilities. Kolmogorov´s axioms, in simplicity, are three:

**Non-negativity** -- The probability of a random event is not a negative number: $P(A) \geq 0$

**Normalisation** -- The probability of an entire sample space is 1: $P(S)=1$

**Additivity** -- For mutually exclusive random events A and B, the probability of their union is the sum of their probabilities: $P(A\cap B)=0\rightarrow P(A\cup B)=P(A)+P(B)$

Based on these three axioms, all the rules for computing with probabilities can be derived. The most essential derivations are:

The probability of an empty set is 0: $P(\emptyset )=0$

The probability of a random event is between 0 and 1: $0 \leq P(A)\leq 1$

The probability of a complement is: $P(\bar{A})=1-P(A)$

The probability of a union is: $P(A \cup B)=P(A)+P(B)-P(A \cap B)$

## Transformations of Probability

It is derived from Kolmogorov´s axioms, which state that probability is a number between 0 and 1. However, for statistical modelling and sometimes in the usual language, we need numbers related to the probability but used on a different scale. This is what various transformations of probability ensure.

### Odds

Odds are an everyday linguistic use of probability, often seen in betting, that is a transformation:

$$ Odds(A)=\frac {P(A)}{P(\bar A)}= \frac {P(A)}{1-P(A)} $$

The transformation lands on the scale $(0, \infty)$.

So, instead of saying that the probability of a home team winning a soccer match is 0.2, this probability is one to four because odds equal 0.2 over 0.8 equals one fourth. Odds can also be used to calculate the Bayes formula.

### Logit

Expressing probability on the unbounded scale might be helpful for linear statistical modelling. This is where logit, using natural base logarithm, comes in handy:

$$ Logit(A)=log(odds(A))=log \left( \frac {P(A)}{1-P(A)} \right) $$

### Negative log transformation

This type of transformation is vital in information theory, where we transform probability on the positive scale $(0, \infty)$, expressing the surprisingness levels of random events. The base of the logarithm tells us the information units, e.g. base = 2 leads to the result expressed in bits.

$$ -log_2(P(A)) $$

## Two Random Events

Considering two (or more, of course) random events, we can introduce important statistical concepts -- conditionality and (in)dependence.

### Independent random events

The two random events, coming from two random trials, are independent if the result of one of the trials does not influence the probabilities of the results of the other trial, and vice versa.

We note conditional probability as $P(A|B)$, meaning the probability of A under the condition of B. The fact that the change in condition does not change this probability can be expressed as

$$ P(A|B)=P(A|\bar B)=P(A) $$

and vice versa.

Let´s make a quick detour. What is the probability of the intersection of two random events? Intersection means that both events occur. The product of two probabilities gives the probability of two events occurring, but which? Having random events A and B, we can say that both occur is equivalent to A occurring and B occurring under condition A has occurred. And vice versa, so

$$ P(A \cap B)=P(A)*P(B|A)=P(B)*P(A|B) $$

With this detour, we can posit **necessary and sufficient condition of independence:**

$$ P(A \cap B)=P(A)*P(B) $$

If two random events are independent, the probability of their intersection is a product of individual probabilities. And if the product of individual probabilities is equal to the probability of intersection, the two random events are independent. This has two critical consequences -- first, it simplifies calculation if we assume independence (e.g., standard likelihood function used in estimation theory). Second, it can be used to test the hypothesis of independence when having a set of data.

### Conditional probability

Last but not least comes an essential formula: conditional probability calculation. Since we introduced that $P(A \cap B)=P(A)*P(B|A)$, it should be easy to see how to calculate

$$ P(B|A)=\frac{P(A \cap B)}{P(A)} $$

and vice versa.

This can be interpreted this way: the probability of B under the condition of A is the probability of both events occurring divided by the probability of the condition P(A). The condition limits the sample space, leading to normalisation such that

$$ P(B|A)+P(\bar B|A)=\frac {P(A \cap B)}{P(A)} + \frac {P(A \cap \bar B)}{P(A)}=\frac{P(A \cap B)+P(A\cap \bar B)}{P(A)}=\frac {P(A)}{P(A)}=1 $$

Yes, under condition A, either B or complement to B must happen.

## Total Probability Law

In the previous part of the lecture notes, we defined conditional probability. We will continue in the journey to reach two very important results of probability theory - total probability law now and Bayes theorem in the next part.

Let´s start with the simplest case: we have one random event B followed by the second random event A. Random event A is dependent on the random event B, meaning its conditional probabilities are different based on whether event B or its complement occurred: $P(A|B) \not= P(A|\bar{B})$.

The first question arises: what is (un)conditional probability of the random event A? If we think a little while about this, the four intersections create elementary sample space:

$E=(A\cap{B}, A\cap{\bar{B}}, \bar{A}\cap{B}), \bar{A}\cap{\bar{B}})$.

Random event A is simply union: $A=(A\cap{B})\cup({A\cap{\bar{B}}})$.

And since the two intersections are elementary, they are disjoint and the probability of such a union:

$P(A)=P(A\cap{B})+P({A\cap{\bar{B}}})$.

In simple terms, the random event A occurs if random event A occurs with B or with the complement to B, and total probability is the summation of the two possibilities. If we apply the formula from the previous section, we can find the usual way total probability law is written in this case:

$P(A)=P(B)*P(A|B)+P(\bar{B})*P(A|\bar{B})$.

In the last step, we can generalise. Instead of the random event B and its complement, let´s now assume that the first random trial can end up in *k* various disjoint random events, which together fully partition the sample space of this random trial:

$E=\cup_{i=1}^kB_i$.

Hence, the summation of probabilities of $B_i$ is equal to one:

$\sum_{i=1}^k(P(B_i))=1$.

Then we can follow the same logic as in the first case, where *k* = 2, and find out the general formula for total probability law:

$P(A)=\sum_{i=1}^k(P(B_i)*P(A|B_i))$.

We can interpret this formula - total probability is the weighted average of the conditional probabilities $P(A|B_i)$ with weights equal to respective probabilities of conditions $P(B_i)$.

## Bayes Theorem

We used total probability law to determine event A's probability independent of the preceding event B. But we can be, and often are, interested in a different question: knowing that event A happened, what is the probability that before it, event B happened?

This question was generally answered in the late 18th century independently by two persons: first by English reverend Thomas Bayes, whose work was corrected and published posthumously by his friend Richard Price, and later and more generally by Pierre-Simon Laplace, who put the ground to what is now called Bayesian inference. The last name to mention here is Sir Jeffreys, who put Laplace´s formulation in line with the axiomatic definition of probability.

It is important to note that even though Bayes´ theorem is a basis for Bayesian inference (statistic) and was developed as such, it is generally an undisputable and uncontroversial finding in probability theory.

Let´s start with $P(B|A)=\frac{P(A\cap B)}{P(A)}$; then P(A) is given by total probability law, hence:

$$ P(B|A)=\frac{P(A\cap B)}{P(A\cap B)+P(A\cap \bar{B})} $$

We can interpret it, e.g., in this way: What part of the total probability of event A is attributable to events A and B occurring together? In a more general way, this specific case of Bayes theorem can be written using the notation from the previous section:

$$ P(B_{i}|A)=\frac{P(A\cap B_{i})}{\sum_{i=1}^kP(B_i) *P(A|B_i)} $$

In statistics, probabilities $P(B_i)$ are usually called prior probabilities or simply priors to stress that they represent probability before an event A does or does not occur (before data). Probabilities $P(A|B_i)$ are in statistics called likelihoods (probabilities of data). Finally, probabilities $P(B_i|A)$ are called posterior probabilities or simply posteriors because they represent newly acquired probabilities after observing event A (after seeing data).
