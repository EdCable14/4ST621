<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Adam Cabla">

<title>4ST621 - Basics of Probability</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">4ST621</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./Course_Intro.html" rel="" target="" aria-current="page">
 <span class="menu-text">Course Introduction</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./LN1.html">Probability Theory</a></li><li class="breadcrumb-item"><a href="./LN1.html">Basics of Probability</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Course_Intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Probability Theory</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Basics of Probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Variable</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Characteristics of Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Vectors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Selected Discrete Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Selected Continuous Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Two Selected Multivariate Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Stochastic convergences</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Mathematical Statistics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LN10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Point estimates</span></a>
  </div>
</li>
          <li class="sidebar-item">
 <span class="menu-text">LN11.qmd</span>
  </li>
          <li class="sidebar-item">
 <span class="menu-text">LN12.qmd</span>
  </li>
          <li class="sidebar-item">
 <span class="menu-text">LN13.qmd</span>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#interpretation-of-probability" id="toc-interpretation-of-probability" class="nav-link active" data-scroll-target="#interpretation-of-probability">Interpretation of Probability</a></li>
  <li><a href="#definitions-of-probability" id="toc-definitions-of-probability" class="nav-link" data-scroll-target="#definitions-of-probability">Definitions of Probability</a>
  <ul class="collapse">
  <li><a href="#the-classical-definition-of-probability" id="toc-the-classical-definition-of-probability" class="nav-link" data-scroll-target="#the-classical-definition-of-probability">The classical definition of probability</a></li>
  <li><a href="#geometric-definition-of-probability" id="toc-geometric-definition-of-probability" class="nav-link" data-scroll-target="#geometric-definition-of-probability">Geometric definition of probability</a></li>
  <li><a href="#frequentist-definition-of-probability" id="toc-frequentist-definition-of-probability" class="nav-link" data-scroll-target="#frequentist-definition-of-probability">Frequentist definition of probability</a></li>
  <li><a href="#axiomatic-definition" id="toc-axiomatic-definition" class="nav-link" data-scroll-target="#axiomatic-definition">Axiomatic definition</a></li>
  </ul></li>
  <li><a href="#transformations-of-probability" id="toc-transformations-of-probability" class="nav-link" data-scroll-target="#transformations-of-probability">Transformations of Probability</a>
  <ul class="collapse">
  <li><a href="#odds" id="toc-odds" class="nav-link" data-scroll-target="#odds">Odds</a></li>
  <li><a href="#logit" id="toc-logit" class="nav-link" data-scroll-target="#logit">Logit</a></li>
  <li><a href="#negative-log-transformation" id="toc-negative-log-transformation" class="nav-link" data-scroll-target="#negative-log-transformation">Negative log transformation</a></li>
  </ul></li>
  <li><a href="#two-random-events" id="toc-two-random-events" class="nav-link" data-scroll-target="#two-random-events">Two Random Events</a>
  <ul class="collapse">
  <li><a href="#independent-random-events" id="toc-independent-random-events" class="nav-link" data-scroll-target="#independent-random-events">Independent random events</a></li>
  <li><a href="#conditional-probability" id="toc-conditional-probability" class="nav-link" data-scroll-target="#conditional-probability">Conditional probability</a></li>
  </ul></li>
  <li><a href="#total-probability-law" id="toc-total-probability-law" class="nav-link" data-scroll-target="#total-probability-law">Total Probability Law</a></li>
  <li><a href="#bayes-theorem" id="toc-bayes-theorem" class="nav-link" data-scroll-target="#bayes-theorem">Bayes Theorem</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Basics of Probability</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Adam Cabla </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="interpretation-of-probability" class="level2">
<h2 class="anchored" data-anchor-id="interpretation-of-probability">Interpretation of Probability</h2>
<p>Let´s begin with the interpretation of probability – what does probability <em>mean</em>?</p>
<p>What does it mean when someone says the “probability of dying at 80 is 0.03”?</p>
<p>What does it mean when someone says the “probability of tomorrow’s rain is 0.5”?</p>
<p>There must be some meaning. Throughout history, two competing schools of probability thought have always existed. One is known as <strong>objectivist</strong>, and the second is known as <strong>subjectivist.</strong></p>
<p>For the first school, the one that dominates this course, probability is an object that we might attempt to discover, but something that exists no matter what we do. Historically, this school has been presented as a physical school, which describes probability as the result of the world’s physics. In a more modern setting, this school is presented more as frequentist, which holds that probability is a limit of relative frequency in a repeated series of random trials.</p>
<p>For the second school, the one that has been somewhat suppressed in the 20th century but is on the rise recently, probability is a subject – something that is dependent on the observer. In this school of thought, the probability is an expression of uncertainty.</p>
<p>While this distinction might, for you, now seem a somewhat interesting but useless philosophical quarrel, it eventually leads to two surprisingly different ways of doing statistical inference, which is in scope in the second half of the course.</p>
</section>
<section id="definitions-of-probability" class="level2">
<h2 class="anchored" data-anchor-id="definitions-of-probability">Definitions of Probability</h2>
<p>In the previous part, the focus was on the interpretation of probability. Let´s now discuss the definition of probability. These are hard to separate from the interpretation and, in some cases, are tightly connected.</p>
<section id="the-classical-definition-of-probability" class="level3">
<h3 class="anchored" data-anchor-id="the-classical-definition-of-probability">The classical definition of probability</h3>
<p>Historically, formal treatises on probabilities emerged in the 16<sup>th</sup> and 17<sup>th</sup> centuries with scholars dealing with the “game of chance”. These games were based chiefly on throwing dice, but others were also based on cards or roulette wheels. With these games, the idea of a <em>fair outcome</em> emerged – that each outcome at one random trial has equivalent probability. With this assumption, it was easy to calculate probabilities by counts and combinatorics theory, which was emerging to solve many probabilistic puzzles.</p>
<p>What emerged in the works of Italian Gerolamo Cardano is now called <strong>classical definition</strong> and was cemented by Pierre-Simon Laplace. It states that the probability of an event is the ratio of favourable outcomes to all possible outcomes with the principle of difference – no specific outcome is more likely than any other.</p>
<section id="intermezzo---important-terms" class="level4">
<h4 class="anchored" data-anchor-id="intermezzo---important-terms">Intermezzo - Important Terms</h4>
<p><strong>Random trial –</strong>a trial (experiment) in which results cannot be predicted with certainty and repeatable (at least theoretically) under the same conditions.</p>
<p><strong>Random event</strong> – is a result of <strong>random trial</strong>.</p>
<p><strong>Elementary random event</strong> – is <em>the smallest possible outcome</em> of a random trial. More formally, it is such a random event that the union of other random events cannot create it. Is indivisible.</p>
<p><strong>Sample space E</strong> – is a set of all possible elementary random events.</p>
<p><strong>Random events</strong> (usually denoted by capital letters from the beginning of the alphabet – A, B, C,…)can thus be viewed as any non-empty subset of sample space.</p>
<p><strong>Set operations</strong> are essential for probability calculations because the definitions of the initial terms are based on the sets.</p>
<p><strong>Intersection</strong> <span class="math inline">\(A \cap B\)</span> is a set operation, meaning both A and B are <em>true</em>.</p>
<p><strong>Union</strong> <span class="math inline">\(A \cup B\)</span> is a set operation, meaning at least one of A and B is <em>true.</em></p>
<p><strong>Complement</strong> <span class="math inline">\(\bar A\)</span> is a set operation meaning <em>true if A is not true</em>. Opposite of A.</p>
</section>
<section id="going-back-to-the-classical-definition-of-probability" class="level4">
<h4 class="anchored" data-anchor-id="going-back-to-the-classical-definition-of-probability">Going back to the classical definition of probability</h4>
<p>With new terms, we can define the classical definition of probability as</p>
<p><span class="math display">\[ P(A)= \frac {m}{n} \]</span></p>
<p>Where <em>A</em> is the union of <em>m</em> (number of favourable) random events and <em>n</em> is the number of all possible random events, where individual events are equally likely and mutually exclusive.</p>
</section>
</section>
<section id="geometric-definition-of-probability" class="level3">
<h3 class="anchored" data-anchor-id="geometric-definition-of-probability">Geometric definition of probability</h3>
<p>The classical definition of probability was, among other things, limited by its discrete nature. To overcome this limitation and solve new issuing problems, scholars in the 18th century started thinking about continuous sample spaces. This led to the generalisation called the geometric definition of probability, which can be expressed as</p>
<p><span class="math display">\[ P(A)=\frac {V(A)}{V(E)} \]</span></p>
<p>The V operator represents continuous measure – in one dimension length, in two dimensions area and in more dimensions simply volume. What remained was the idea that each pair of regions of the same volume was equally likely.</p>
<p>The most famous problem solved using the geometric definition of probability was Buffon´s needle: Imagine a floor made of parallel strips of wood, each with the same width <em>t</em>. Now, randomly drop a needle with a length of l onto this floor. How likely is the needle to lie across a line between two strips? This probability, assuming <span class="math inline">\(l \leq t\)</span>, was proved to be</p>
<p><span class="math display">\[ P(A)=\frac {2*l}{\pi*t} \]</span></p>
<p>Much later, this problem was turned around, and Buffon´s needle was used to estimate the value of <span class="math inline">\(π\)</span> by substituting relative frequency <em>p</em> for probability P(A):</p>
<p><span class="math display">\[ est(\pi)=\frac{2*l} {p *t} \]</span></p>
<p>Substituting relative frequency for probability is a trick available thanks to the laws describing convergences in probability and is the basis of the frequentist definition.</p>
</section>
<section id="frequentist-definition-of-probability" class="level3">
<h3 class="anchored" data-anchor-id="frequentist-definition-of-probability">Frequentist definition of probability</h3>
<p>The classical definition of probability stumbled upon a severe limitation – its reliance on the principle of indifference, which might be justifiable in the games of chance but hardly so in other real-world instances. This led to more broad definition of probability.</p>
<p>Have a series of random trials. Based on this series, we have a series of relative frequencies of observing random event A: p<sub>n</sub>(A). This series of relative frequencies will converge (in probability) to its limit, the underlying probability of an event A.</p>
<p><span class="math display">\[p_n(A) \rightarrow P(A)\]</span>We will deal with stochastic convergences later because these laws connect probability theory with statistics.</p>
</section>
<section id="axiomatic-definition" class="level3">
<h3 class="anchored" data-anchor-id="axiomatic-definition">Axiomatic definition</h3>
<p>Around the same time R.A. Fischer or Richard von Misses (brother of not less famous Austrian economist Ludwig von Misses) were championing and rigorously proving frequentist definition and interpretation of probability, a completely new approach emerged: axiomatic definition, work of brilliant Russian mathematician A. N. Kolmogorov. This approach focused on the smallest basic set of rules, axioms, which can serve as a basis for all manipulations with probabilities. Kolmogorov´s axioms, in simplicity, are three:</p>
<p><strong>Non-negativity</strong> – The probability of a random event is not a negative number: <span class="math inline">\(P(A) \geq 0\)</span></p>
<p><strong>Normalisation</strong> – The probability of an entire sample space is 1: <span class="math inline">\(P(S)=1\)</span></p>
<p><strong>Additivity</strong> – For mutually exclusive random events A and B, the probability of their union is the sum of their probabilities: <span class="math inline">\(P(A\cap B)=0\rightarrow P(A\cup B)=P(A)+P(B)\)</span></p>
<p>Based on these three axioms, all the rules for computing with probabilities can be derived. The most essential derivations are:</p>
<p>The probability of an empty set is 0: <span class="math inline">\(P(\emptyset )=0\)</span></p>
<p>The probability of a random event is between 0 and 1: <span class="math inline">\(0 \leq P(A)\leq 1\)</span></p>
<p>The probability of a complement is: <span class="math inline">\(P(\bar{A})=1-P(A)\)</span></p>
<p>The probability of a union is: <span class="math inline">\(P(A \cup B)=P(A)+P(B)-P(A \cap B)\)</span></p>
</section>
</section>
<section id="transformations-of-probability" class="level2">
<h2 class="anchored" data-anchor-id="transformations-of-probability">Transformations of Probability</h2>
<p>It is derived from Kolmogorov´s axioms, which state that probability is a number between 0 and 1. However, for statistical modelling and sometimes in the usual language, we need numbers related to the probability but used on a different scale. This is what various transformations of probability ensure.</p>
<section id="odds" class="level3">
<h3 class="anchored" data-anchor-id="odds">Odds</h3>
<p>Odds are an everyday linguistic use of probability, often seen in betting, that is a transformation:</p>
<p><span class="math display">\[ Odds(A)=\frac {P(A)}{P(\bar A)}= \frac {P(A)}{1-P(A)} \]</span></p>
<p>The transformation lands on the scale <span class="math inline">\((0, \infty)\)</span>.</p>
<p>So, instead of saying that the probability of a home team winning a soccer match is 0.2, this probability is one to four because odds equal 0.2 over 0.8 equals one fourth. Odds can also be used to calculate the Bayes formula.</p>
</section>
<section id="logit" class="level3">
<h3 class="anchored" data-anchor-id="logit">Logit</h3>
<p>Expressing probability on the unbounded scale might be helpful for linear statistical modelling. This is where logit, using natural base logarithm, comes in handy:</p>
<p><span class="math display">\[ Logit(A)=log(odds(A))=log \left( \frac {P(A)}{1-P(A)} \right) \]</span></p>
</section>
<section id="negative-log-transformation" class="level3">
<h3 class="anchored" data-anchor-id="negative-log-transformation">Negative log transformation</h3>
<p>This type of transformation is vital in information theory, where we transform probability on the positive scale <span class="math inline">\((0, \infty)\)</span>, expressing the surprisingness levels of random events. The base of the logarithm tells us the information units, e.g.&nbsp;base = 2 leads to the result expressed in bits.</p>
<p><span class="math display">\[ -log_2(P(A)) \]</span></p>
</section>
</section>
<section id="two-random-events" class="level2">
<h2 class="anchored" data-anchor-id="two-random-events">Two Random Events</h2>
<p>Considering two (or more, of course) random events, we can introduce important statistical concepts – conditionality and (in)dependence.</p>
<section id="independent-random-events" class="level3">
<h3 class="anchored" data-anchor-id="independent-random-events">Independent random events</h3>
<p>The two random events, coming from two random trials, are independent if the result of one of the trials does not influence the probabilities of the results of the other trial, and vice versa.</p>
<p>We note conditional probability as <span class="math inline">\(P(A|B)\)</span>, meaning the probability of A under the condition of B. The fact that the change in condition does not change this probability can be expressed as</p>
<p><span class="math display">\[ P(A|B)=P(A|\bar B)=P(A) \]</span></p>
<p>and vice versa.</p>
<p>Let´s make a quick detour. What is the probability of the intersection of two random events? Intersection means that both events occur. The product of two probabilities gives the probability of two events occurring, but which? Having random events A and B, we can say that both occur is equivalent to A occurring and B occurring under condition A has occurred. And vice versa, so</p>
<p><span class="math display">\[ P(A \cap B)=P(A)*P(B|A)=P(B)*P(A|B) \]</span></p>
<p>With this detour, we can posit <strong>necessary and sufficient condition of independence:</strong></p>
<p><span class="math display">\[ P(A \cap B)=P(A)*P(B) \]</span></p>
<p>If two random events are independent, the probability of their intersection is a product of individual probabilities. And if the product of individual probabilities is equal to the probability of intersection, the two random events are independent. This has two critical consequences – first, it simplifies calculation if we assume independence (e.g., standard likelihood function used in estimation theory). Second, it can be used to test the hypothesis of independence when having a set of data.</p>
</section>
<section id="conditional-probability" class="level3">
<h3 class="anchored" data-anchor-id="conditional-probability">Conditional probability</h3>
<p>Last but not least comes an essential formula: conditional probability calculation. Since we introduced that <span class="math inline">\(P(A \cap B)=P(A)*P(B|A)\)</span>, it should be easy to see how to calculate</p>
<p><span class="math display">\[ P(B|A)=\frac{P(A \cap B)}{P(A)} \]</span></p>
<p>and vice versa.</p>
<p>This can be interpreted this way: the probability of B under the condition of A is the probability of both events occurring divided by the probability of the condition P(A). The condition limits the sample space, leading to normalisation such that</p>
<p><span class="math display">\[ P(B|A)+P(\bar B|A)=\frac {P(A \cap B)}{P(A)} + \frac {P(A \cap \bar B)}{P(A)}=\frac{P(A \cap B)+P(A\cap \bar B)}{P(A)}=\frac {P(A)}{P(A)}=1 \]</span></p>
<p>Yes, under condition A, either B or complement to B must happen.</p>
</section>
</section>
<section id="total-probability-law" class="level2">
<h2 class="anchored" data-anchor-id="total-probability-law">Total Probability Law</h2>
<p>In the previous part of the lecture notes, we defined conditional probability. We will continue in the journey to reach two very important results of probability theory - total probability law now and Bayes theorem in the next part.</p>
<p>Let´s start with the simplest case: we have one random event B followed by the second random event A. Random event A is dependent on the random event B, meaning its conditional probabilities are different based on whether event B or its complement occurred: <span class="math inline">\(P(A|B) \not= P(A|\bar{B})\)</span>.</p>
<p>The first question arises: what is (un)conditional probability of the random event A? If we think a little while about this, the four intersections create elementary sample space:</p>
<p><span class="math inline">\(E=(A\cap{B}, A\cap{\bar{B}}, \bar{A}\cap{B}), \bar{A}\cap{\bar{B}})\)</span>.</p>
<p>Random event A is simply union: <span class="math inline">\(A=(A\cap{B})\cup({A\cap{\bar{B}}})\)</span>.</p>
<p>And since the two intersections are elementary, they are disjoint and the probability of such a union:</p>
<p><span class="math inline">\(P(A)=P(A\cap{B})+P({A\cap{\bar{B}}})\)</span>.</p>
<p>In simple terms, the random event A occurs if random event A occurs with B or with the complement to B, and total probability is the summation of the two possibilities. If we apply the formula from the previous section, we can find the usual way total probability law is written in this case:</p>
<p><span class="math inline">\(P(A)=P(B)*P(A|B)+P(\bar{B})*P(A|\bar{B})\)</span>.</p>
<p>In the last step, we can generalise. Instead of the random event B and its complement, let´s now assume that the first random trial can end up in <em>k</em> various disjoint random events, which together fully partition the sample space of this random trial:</p>
<p><span class="math inline">\(E=\cup_{i=1}^kB_i\)</span>.</p>
<p>Hence, the summation of probabilities of <span class="math inline">\(B_i\)</span> is equal to one:</p>
<p><span class="math inline">\(\sum_{i=1}^k(P(B_i))=1\)</span>.</p>
<p>Then we can follow the same logic as in the first case, where <em>k</em> = 2, and find out the general formula for total probability law:</p>
<p><span class="math inline">\(P(A)=\sum_{i=1}^k(P(B_i)*P(A|B_i))\)</span>.</p>
<p>We can interpret this formula - total probability is the weighted average of the conditional probabilities <span class="math inline">\(P(A|B_i)\)</span> with weights equal to respective probabilities of conditions <span class="math inline">\(P(B_i)\)</span>.</p>
</section>
<section id="bayes-theorem" class="level2">
<h2 class="anchored" data-anchor-id="bayes-theorem">Bayes Theorem</h2>
<p>We used total probability law to determine event A’s probability independent of the preceding event B. But we can be, and often are, interested in a different question: knowing that event A happened, what is the probability that before it, event B happened?</p>
<p>This question was generally answered in the late 18th century independently by two persons: first by English reverend Thomas Bayes, whose work was corrected and published posthumously by his friend Richard Price, and later and more generally by Pierre-Simon Laplace, who put the ground to what is now called Bayesian inference. The last name to mention here is Sir Jeffreys, who put Laplace´s formulation in line with the axiomatic definition of probability.</p>
<p>It is important to note that even though Bayes´ theorem is a basis for Bayesian inference (statistic) and was developed as such, it is generally an undisputable and uncontroversial finding in probability theory.</p>
<p>Let´s start with <span class="math inline">\(P(B|A)=\frac{P(A\cap B)}{P(A)}\)</span>; then P(A) is given by total probability law, hence:</p>
<p><span class="math display">\[ P(B|A)=\frac{P(A\cap B)}{P(A\cap B)+P(A\cap \bar{B})} \]</span></p>
<p>We can interpret it, e.g., in this way: What part of the total probability of event A is attributable to events A and B occurring together? In a more general way, this specific case of Bayes theorem can be written using the notation from the previous section:</p>
<p><span class="math display">\[ P(B_{i}|A)=\frac{P(A\cap B_{i})}{\sum_{i=1}^kP(B_i) *P(A|B_i)} \]</span></p>
<p>In statistics, probabilities <span class="math inline">\(P(B_i)\)</span> are usually called prior probabilities or simply priors to stress that they represent probability before an event A does or does not occur (before data). Probabilities <span class="math inline">\(P(A|B_i)\)</span> are in statistics called likelihoods (probabilities of data). Finally, probabilities <span class="math inline">\(P(B_i|A)\)</span> are called posterior probabilities or simply posteriors because they represent newly acquired probabilities after observing event A (after seeing data).</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>